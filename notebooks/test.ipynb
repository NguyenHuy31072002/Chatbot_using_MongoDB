{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np \n",
    "\n",
    "# https://huggingface.co/datasets/MongoDB/embedded_movies\n",
    "dataset_df = pd.read_csv(r\"C:\\Users\\PC\\Downloads\\Luat_VN.csv\")\n",
    "\n",
    "dataset_df\n",
    "\n",
    "# https://huggingface.co/thenlper/gte-large\n",
    "embedding_model = SentenceTransformer(\"keepitreal/vietnamese-sbert\")\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    if not text.strip():\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = embedding_model.encode(text)\n",
    "\n",
    "    return embedding.tolist()\n",
    "dataset_df[\"embedding\"] = dataset_df[\"Điều Luật\"].apply(get_embedding)\n",
    "\n",
    "# Kết nối với MongDB và thực hiện lưu trữ\n",
    "\n",
    "\n",
    "def get_mongo_client(mongo_uri):\n",
    "  \"\"\"Establish connection to the MongoDB.\"\"\"\n",
    "  try:\n",
    "    client = pymongo.MongoClient(mongo_uri, appname=\"devrel.content.python\")\n",
    "    print(\"Connection to MongoDB successful\")\n",
    "    return client\n",
    "  except pymongo.errors.ConnectionFailure as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "    return None\n",
    "\n",
    "mongo_uri = \"mongodb+srv://khachuy2002:v7K5xIz5BU5MPCnX@cluster0.mvyocg9.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "if not mongo_uri:\n",
    "  print(\"MONGO_URI not set in environment variables\")\n",
    "\n",
    "mongo_client = get_mongo_client(mongo_uri)\n",
    "# Ingest data into MongoDB\n",
    "db = mongo_client['sample_mflix']\n",
    "collection = db['movie_collection_2']\n",
    "mongo_client['sample_mflix']['movie_collection_2'].count_documents({})\n",
    "# Delete any existing records in the collection\n",
    "collection.delete_many({})\n",
    "\n",
    "documents = dataset_df.to_dict(\"records\")\n",
    "collection.insert_many(documents)\n",
    "print(\"Data ingestion into MongoDB completed\")\n",
    "# Sử dụng công nghệ MB25 và vector search\n",
    "data = collection.find()\n",
    "df = pd.DataFrame(list(data))\n",
    "df= df.drop(['_id', 'Unnamed: 0'], axis=1)\n",
    "tokenized_corpus = df['Điều Luật'].apply(lambda doc: doc.split(\" \")).tolist()\n",
    "#Khỏi tạo Bm25\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "# Khỏi tạo model \n",
    "model = SentenceTransformer(\"keepitreal/vietnamese-sbert\")\n",
    "# tạo nhúng cho văn bản và truy vấn\n",
    "corpus_ebeddings = model.encode(df['Điều Luật'].tolist(), convert_to_tensor=True)\n",
    "# Truy vấn\n",
    "query = \"Miêu tả về Nguyễn Khắc Huy\"\n",
    "query_tokens = query.split(\" \")\n",
    "bm25_scores = bm25.get_scores(query_tokens)\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "# Tính điểm tương tự giữa truy vấn với tài liệu\n",
    "vector_scores = util.pytorch_cos_sim(query_embedding,corpus_ebeddings)\n",
    "# Kết hợp BM25 và điểm vector \n",
    "combined_scores = np.array(bm25_scores) * vector_scores.cpu().numpy().flatten()\n",
    "# Xác định chỉ số của tài liệu có điểm cao nhất \n",
    "max_score_index = np.argmax(combined_scores)\n",
    "max_score = combined_scores[max_score_index]\n",
    "# Hiển thị tài liệu có điểm cao nhất \n",
    "best_document = df.iloc[max_score_index]\n",
    "print(f\"Tài liệu có điểm cao nhất:\\nID:{best_document['id']}\\nĐiều Luật: {best_document['Điều Luật']}\\n Điểm kết hợp: {max_score}\\n\")\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Cấu hình mô hình generative\n",
    "genai.configure(api_key=\"AIzaSyCZh9YLA0zKAlm8NnKKucNd2u-VJNI59ew\")\n",
    "llm_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Truy vấn\n",
    "query = \"Tôi muốn biết về Nguyễn Khắc Huy\"\n",
    "query_tokens = query.split(\" \")\n",
    "\n",
    "# Tính điểm BM25\n",
    "bm25_scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "# Tính điểm vector\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "vector_scores = util.pytorch_cos_sim(query_embedding, corpus_ebeddings)\n",
    "\n",
    "# Kết hợp BM25 và điểm vector\n",
    "combined_scores = np.array(bm25_scores) * vector_scores.cpu().numpy().flatten()\n",
    "\n",
    "# Xác định chỉ số của tài liệu có điểm cao nhất\n",
    "max_score_index = np.argmax(combined_scores)\n",
    "max_score = combined_scores[max_score_index]\n",
    "\n",
    "# Hiển thị tài liệu có điểm cao nhất\n",
    "best_document = df.iloc[max_score_index]\n",
    "print(f\"Tài liệu có điểm cao nhất:\\nID:{best_document['id']}\\nĐiều Luật: {best_document['Điều Luật']}\\nĐiểm kết hợp: {max_score}\\n\")\n",
    "\n",
    "# Điều kiện sử dụng LLM\n",
    "if max_score < 6:\n",
    "    # Sử dụng LLM để tạo câu trả lời từ truy vấn\n",
    "    combined_information = f\"Truy vấn: {query}\\nHãy trả lời như một chuyên gia về lĩnh vực liên quan đến pháp luật Việt Nam.\"\n",
    "    llm_response = llm_model.generate_content(combined_information)\n",
    "    print(\"Trả lời từ LLM:\")\n",
    "    print(llm_response.text)\n",
    "else:\n",
    "    # Sử dụng LLM để tạo câu trả lời từ tài liệu\n",
    "    combined_information = f\"Truy vấn: {query}\\nHãy trả lời như một chuyên gia về lĩnh vực liên quan đến pháp luật Việt Nam và dựa vào các điều luật trong đây: {best_document['Điều Luật']}.\"\n",
    "    llm_response = llm_model.generate_content(combined_information)\n",
    "    print(\"Trả lời từ LLM dựa vào tài liệu:\")\n",
    "    print(llm_response.text)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
